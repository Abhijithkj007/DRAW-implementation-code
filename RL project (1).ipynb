{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85105d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45487a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebb877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0166ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f61670de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'draw_model_22' (type DRAWModel).\n\n{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [64,28,28] vs. [64,28,28,1] [Op:Sub]\n\nCall arguments received by layer 'draw_model_22' (type DRAWModel):\n  • x=tf.Tensor(shape=(64, 28, 28), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 161>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    166\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m x_train[batch \u001b[38;5;241m*\u001b[39m batch_size: (batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size]\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m--> 168\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss_fn(x_batch, outputs)\n\u001b[0;32m    170\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_value, draw_model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mDRAWModel.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mless(t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_steps)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Execute the recurrent steps of the DRAW model\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     _, _, _, _, final_canvas \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_recurrence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_recurrent_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_canvas\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mDRAWModel.call.<locals>.draw_recurrent_step\u001b[1;34m(t, x, h_dec_prev, enc_state, canvas)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_recurrent_step\u001b[39m(t, x, h_dec_prev, enc_state, canvas):\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Read operation\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     read_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(x, x_hat, h_dec_prev)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Encoder operation\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'draw_model_22' (type DRAWModel).\n\n{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [64,28,28] vs. [64,28,28,1] [Op:Sub]\n\nCall arguments received by layer 'draw_model_22' (type DRAWModel):\n  • x=tf.Tensor(shape=(64, 28, 28), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Define the DRAW model class\n",
    "class DRAWModel(tf.keras.Model):\n",
    "    def __init__(self, img_size, num_steps, batch_size):\n",
    "        super(DRAWModel, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Define the LSTM cell for the encoder and decoder\n",
    "        self.lstm_enc = tf.keras.layers.LSTMCell(units=256)\n",
    "        self.lstm_dec = tf.keras.layers.LSTMCell(units=256)\n",
    "\n",
    "        # Define the learnable parameters for the model\n",
    "        self.W_enc = tf.Variable(tf.random.normal([256, 10]), name='W_enc')\n",
    "        self.b_enc = tf.Variable(tf.zeros([10]), name='b_enc')\n",
    "\n",
    "        self.W_dec = tf.Variable(tf.random.normal([256, self.img_size * self.img_size]), name='W_dec')\n",
    "        self.b_dec = tf.Variable(tf.zeros([self.img_size * self.img_size]), name='b_dec')\n",
    "\n",
    "    def encode(self, enc_state, input):\n",
    "        _, enc_state = self.lstm_enc(input, enc_state)\n",
    "        return enc_state\n",
    "\n",
    "    def decode(self, dec_state, input):\n",
    "        _, dec_state = self.lstm_dec(input, dec_state)\n",
    "        return dec_state\n",
    "\n",
    "    def read(self, x, x_hat, h_dec_prev):\n",
    "        # Define the parameters for the read operation\n",
    "        kernel_size = 3\n",
    "        stride = 2\n",
    "\n",
    "        # Compute the read window using a convolutional filter\n",
    "        read_window = tf.image.extract_patches(\n",
    "            images=x_hat,\n",
    "            sizes=[1, kernel_size, kernel_size, 1],\n",
    "            strides=[1, stride, stride, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='SAME'\n",
    "        )\n",
    "\n",
    "        # Reshape the read window to match the LSTM input shape\n",
    "        read_window = tf.reshape(read_window, [self.batch_size, -1])\n",
    "\n",
    "        # Concatenate the read window with the previous decoder hidden state\n",
    "        read_input = tf.concat([read_window, h_dec_prev], axis=1)\n",
    "\n",
    "\n",
    "        return read_input\n",
    "\n",
    "    def write(self, h_dec, canvas):\n",
    "        # Map the hidden state to the canvas size\n",
    "        write_output = tf.matmul(h_dec, self.W_dec) + self.b_dec\n",
    "\n",
    "        # Reshape the write output to match the canvas shape\n",
    "        write_output = tf.reshape(write_output, [self.batch_size, self.img_size, self.img_size])\n",
    "\n",
    "        # Add the write output to the canvas using element-wise addition\n",
    "        canvas += write_output\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    def attention(self, h_dec, enc_state,x):\n",
    "        # Compute glimpse window\n",
    "        glimpse = self.read(x, h_dec)\n",
    "\n",
    "        # Apply attention mechanism\n",
    "        glimpse = tf.reshape(glimpse, [self.batch_size, -1])\n",
    "        glimpse_attention = tf.nn.softmax(tf.matmul(glimpse, self.W_enc) + self.b_enc, axis=1)\n",
    "\n",
    "        # Compute weighted sum of glimpse window\n",
    "        glimpse_vector = tf.reduce_sum(glimpse * tf.expand_dims(glimpse_attention, axis=2), axis=1)\n",
    "\n",
    "        return glimpse_vector\n",
    "\n",
    "    def call(self, x):\n",
    "    # Expand dimensions of input tensor\n",
    "#         x = tf.expand_dims(x, axis=-1)\n",
    "\n",
    "    # Reshape input tensor to have 4 dimensions\n",
    "#         x = tf.reshape(x, [self.batch_size, self.img_size, self.img_size, 1])\n",
    "\n",
    "    # Define the initial states for the encoder and decoder LSTM\n",
    "        self.enc_state = [tf.zeros([self.batch_size, 256]), tf.zeros([self.batch_size, 256])]\n",
    "        self.dec_state = [tf.zeros([self.batch_size, 256]), tf.zeros([self.batch_size, 256])]\n",
    "\n",
    "    # Define the initial canvas\n",
    "        self.canvas = tf.zeros([self.batch_size, self.img_size, self.img_size, 1])\n",
    "\n",
    "    # Define the recurrent steps of the DRAW model\n",
    "        def draw_recurrent_step(t, x, h_dec_prev, enc_state, canvas):\n",
    "        # Read operation\n",
    "            x_hat = x - tf.sigmoid(canvas)\n",
    "            read_window = self.read(x, x_hat, h_dec_prev)\n",
    "\n",
    "        # Encoder operation\n",
    "            r, enc_state = self.encode(enc_state, tf.concat([read_window, h_dec_prev], axis=1))\n",
    "\n",
    "        # Attention operation\n",
    "            z = self.attention(r, enc_state, x)  # Pass x to the attention method\n",
    "\n",
    "        # Decoder operation\n",
    "            h_dec, dec_state = self.decode(self.dec_state, z)\n",
    "\n",
    "        # Write operation\n",
    "            canvas = self.write(h_dec, canvas)\n",
    "    \n",
    "            return t + 1, x, h_dec, enc_state, canvas\n",
    "\n",
    "    # Define the loop for the recurrent steps\n",
    "        def draw_recurrence(t, x, h_dec_prev, enc_state, canvas):\n",
    "            return tf.less(t, self.num_steps)\n",
    "\n",
    "    # Execute the recurrent steps of the DRAW model\n",
    "        _, _, _, _, final_canvas = tf.while_loop(\n",
    "        cond=draw_recurrence,\n",
    "        body=draw_recurrent_step,\n",
    "        loop_vars=[0, x, self.dec_state, self.enc_state, self.canvas]\n",
    "        )\n",
    "\n",
    "        return final_canvas\n",
    "\n",
    "\n",
    "\n",
    "# Set hyperparameters\n",
    "img_size = 28\n",
    "num_steps = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "# Create an instance of the DRAW model\n",
    "draw_model = DRAWModel(img_size, num_steps, batch_size)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# Compile the model\n",
    "draw_model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    num_batches = x_train.shape[0] // batch_size\n",
    "    for batch in range(num_batches):\n",
    "        x_batch=32\n",
    "        x_batch = x_train[batch * batch_size: (batch + 1) * batch_size]\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = draw_model(x_batch)\n",
    "            loss_value = loss_fn(x_batch, outputs)\n",
    "        gradients = tape.gradient(loss_value, draw_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, draw_model.trainable_variables))\n",
    "        print(f\"Batch {batch + 1}/{num_batches}, Loss: {loss_value:.4f}\")\n",
    "\n",
    "    # Evaluate the model on test data after each epoch\n",
    "    test_outputs = draw_model(x_test)\n",
    "    test_loss = loss_fn(x_test, test_outputs)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Generate reconstructions on test data\n",
    "reconstructions = draw_model(x_test).numpy()\n",
    "\n",
    "# Display original images and their reconstructions\n",
    "n = 10  # number of images to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original image\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"Original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructions[i])\n",
    "    plt.title(\"Reconstruction\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb4a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
